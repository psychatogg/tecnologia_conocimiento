---
title: "Práctica de Redes de Convolución"
author: "Juliana Quirós, Alberto"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(formatR)
library(kableExtra)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60),echo = FALSE,tidy=TRUE, warning=FALSE, out.width = "70%")
```

1.  \

    ![](diagrama/diagrama.png)

2.1.\
Estas fueron las tasas probadas:

```{r}
tasas_1 <- read.csv("E:\\GDrive1\\Uni\\Master\\tecnologia_conocimiento\\practicas\\convolucional\\2.1_tasas1.csv",sep=";", header=TRUE)
tm <- tasas_1[3,1]
em <- max(tasas_1$exactitud)
knitr::kable(tasas_1, format = "markdown", digits = 6, 
             row.names = FALSE, align = c("l", "c", "r"))
             
```

La em es de `r em`%, con una tm=`r tm`.\
\

```{r}
library(ggplot2)
tasas_2 <- read.csv("E:\\GDrive1\\Uni\\Master\\tecnologia_conocimiento\\practicas\\convolucional\\2.1_tasas2.csv",sep=";", header=TRUE)

tasas_2$nombre <- factor(tasas_2$nombre, levels=(tasas_2$nombre))


             
```

\

```{r}
ggplot(tasas_2, aes(x=nombre, y=exactitud, group=1)) + 
  geom_point(color="blue") +
	geom_line() +
  labs(x="Tasa de aprendizaje", y="Exactitud (%)") +
  ggtitle("Gráfico de tasas de aprendizaje y exactitud")
```

\
2.2\

```{r}
library(tidyr)
tasas_3 <- read.csv("E:\\GDrive1\\Uni\\Master\\tecnologia_conocimiento\\practicas\\convolucional\\2.2_tasas.csv",sep=";", header=TRUE)

tasas_3_long <- gather(tasas_3, key = "exactitud", value = "valor_exactitud", exactitud_10:exactitud_50, factor_key = TRUE)



tasas_3_long$nombre <- factor(tasas_3_long$nombre)
levels(tasas_3_long$nombre) <- c("tm_div20", "tm_div15", "tm_div10", "tm_div5", "tm", "tm_5", "tm_10", "tm_15", "tm_20")
levels(tasas_3_long$exactitud) <- c("1", "2", "3", "4", "5")

```

![](2.2_plot.png) Medias de exactitud por épocas:\

```{r}
medias_exact <- data.frame(t(apply(tasas_3[,3:7],2,function(x) mean(x))))
knitr::kable(medias_exact, format = "markdown", digits = 6, 
             row.names = FALSE, align = c("l", "c", "r"))
```

\
2.3\
Como podemos observar, obtenemos una mayor exactitud con tasas de aprendizaje más pequeñas que con múltiplos de la máxima. Esto puede deberse a que el algoritmo converge en una solución subóptima (mínimo local) en los primeros casos, frente a la omisión directa de dichos mínimos en los segundos casos, que inducen errores de detección y clasificación.\
Observamos a su vez, que la tasa que da lugar a la exactitud máxima se mantiene hasta llegar a 30 épocas. A partir de las 40, tm/5 supera ligeramente a tm. Este fenómeno se debe a que el algoritmo ha dispuesto de mayor tiempo de entrenamiento.\
La media de exactitud más alta (61.8444) se produce con 50 iteraciones, lo cual confirma lo anteriormente expuesto.\
\
3.1\
Basándome en el ejercicio anterior, empleo tm/5 (0.0002) y 50 épocas:

![](learning_curve.png)\
3.2\

```{r}
train_acc <- read.csv("E:\\GDrive1\\Uni\\Master\\tecnologia_conocimiento\\practicas\\convolucional\\train_data.csv", header=FALSE,sep=",", dec=".")
val_acc <- read.csv("E:\\GDrive1\\Uni\\Master\\tecnologia_conocimiento\\practicas\\convolucional\\validation_data.csv", header=FALSE,sep=",",dec=".")
train_acc <- as.numeric(train_acc)
val_acc <- as.numeric(val_acc)
val_acc <- na.omit(val_acc)
med_train <- vector("integer",length=150)
contador <- 1
for (i in 1:150) {
	med_train[i]<- mean(train_acc[contador:contador+49])
	contador <- contador+50
}

## Repito el primer valor de las medias de la base de entrenamiento,dado que las validaciones comienzan previo al primer promediado.
med_train<- append(10,med_train)
```

Empleo la prueba no paramétrica de los signos para 2 muestras, dado que tanto las distribuciones de exactitudes de validación como la de las medias de exactitudes de entrenamiento son muy asimétricas. \

```{r}
wilcox.test(med_train, val_acc, alternative = "two.sided", exact = FALSE, correct = FALSE)
```
Por lo tanto, con un 95% de confianza rechazo la H0 de igualdad de medianas, por lo que existe evidencia estadística de sobreajuste. \
```{r}

minilotes <- seq(1, 151)


plot(minilotes, med_train, type = "l", col = "red", lwd = 2,
     xlab = "Minilotes", ylab = "Media de la precisión",
     main = "Media de la precisión en el training vs validación")
     

lines(minilotes, val_acc, type = "l", col = "blue", lwd = 2)


legend("bottomright", legend = c("Training", "Validación"),
       col = c("red", "blue"), lwd = 2)
axis(1, at=seq(0, 151, by=10))

```

Podemos observar como a partir de, aproximadamente, el minilote 36 (iteración 5400), comienzan a separarse ambos conjuntos de forma sistemática. 
